{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# B0822012邱元肇 樣形識別HW5\n",
        "\n",
        "**作業要求:**\n",
        "\n",
        "上傳第五週回去自己試跑的程式與筆記就可以了\n",
        "\n",
        "**原始程式碼來源:**\n",
        "\n",
        "https://github.com/fchollet/deep-learning-with-python-notebooks\n",
        "\n",
        "chapter05_fundamentals-of-ml.ipynb\n"
      ],
      "metadata": {
        "id": "F3mnV7yweCmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**本章摘要**\n",
        "* 模型訓練上的原理與細節\n",
        "  * 加入白噪音對mnist數據準確度的影響(會降低。可取前10000高頻率字詞訓練避免極端偏差)\n",
        "  * 任意訓練資料模型都能嘗試擬合(但準確度高不代表泛化性佳，故仍需以測試資料評估)\n",
        "* 模型達不到最佳結果\n",
        "  * 設置過高學習率(無法達成理想結果)=>應適當設置\n",
        "  * 模型達不到最佳擬合結果(連過度擬合都沒出現)=>增大模型結構複雜度或神經元，使其存儲更多訊息\n",
        "* 對抗過度擬合\n",
        "  * 縮小模型體積(延緩過度擬合時間，並減緩泛化下降程度)\n",
        "  * 權重正則化：使用L1或L2，以權重納入損失函數之方式限制權重上下限\n",
        "  * Dropout層(取用一定比例的數據將其初始化，使數據增添隨機性)"
      ],
      "metadata": {
        "id": "vYYp1zmGelbs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z-BOxwenkxP"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OnEms08nkxS"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlmDyMwPnkxT"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP9AQPqwnkxT"
      },
      "source": [
        "### Underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf87riy4nkxT"
      },
      "source": [
        "#### Noisy training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3M3Th97nkxU"
      },
      "source": [
        "#### Ambiguous features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW12O-f_nkxU"
      },
      "source": [
        "#### Rare features and spurious correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZPk9PEnnkxU"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**\n",
        "\n",
        "**讀取mnist數據集，並加入噪音**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVlNCp45nkxV",
        "outputId": "ab55e7f0-40a6-480d-d728-dd42f962a7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "# 噪音\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
        "\n",
        "# 零噪音\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zFnmhdP8CVZ",
        "outputId": "d75e6c4b-87b0-4b32-b830-7614b4b54e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_with_noise_channels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9o0PXuW76GE",
        "outputId": "19e02e42-c2cc-406b-bb57-252392d087bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.96498778, 0.67332145,\n",
              "        0.52829696],\n",
              "       [0.        , 0.        , 0.        , ..., 0.78744225, 0.61874876,\n",
              "        0.85970177],\n",
              "       [0.        , 0.        , 0.        , ..., 0.68470674, 0.11706191,\n",
              "        0.42525545],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.43851895, 0.85692664,\n",
              "        0.89222317],\n",
              "       [0.        , 0.        , 0.        , ..., 0.81975925, 0.58491714,\n",
              "        0.29321799],\n",
              "       [0.        , 0.        , 0.        , ..., 0.00842105, 0.70057481,\n",
              "        0.25990934]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_with_zeros_channels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puXBJJ4x8FJr",
        "outputId": "cb475c35-3b3a-4c5d-dc6d-c66e462a3c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLwyvEEvnkxW"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N9Zge40nkxW",
        "outputId": "46d2b1ce-09a6-4b73-fcf4-4a76da286f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 6s 7ms/step - loss: 0.6340 - accuracy: 0.8116 - val_loss: 0.2854 - val_accuracy: 0.9154\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2474 - accuracy: 0.9239 - val_loss: 0.1787 - val_accuracy: 0.9455\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9500 - val_loss: 0.1408 - val_accuracy: 0.9577\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9644 - val_loss: 0.1310 - val_accuracy: 0.9607\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0830 - accuracy: 0.9736 - val_loss: 0.1479 - val_accuracy: 0.9596\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9797 - val_loss: 0.1439 - val_accuracy: 0.9585\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.1206 - val_accuracy: 0.9680\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.1414 - val_accuracy: 0.9621\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.1816 - val_accuracy: 0.9562\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.1348 - val_accuracy: 0.9685\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2882 - accuracy: 0.9163 - val_loss: 0.1660 - val_accuracy: 0.9542\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9642 - val_loss: 0.1196 - val_accuracy: 0.9631\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9769 - val_loss: 0.1007 - val_accuracy: 0.9706\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0581 - accuracy: 0.9830 - val_loss: 0.0890 - val_accuracy: 0.9749\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9875 - val_loss: 0.0816 - val_accuracy: 0.9778\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 0.0891 - val_accuracy: 0.9741\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0868 - val_accuracy: 0.9767\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0804 - val_accuracy: 0.9783\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.0777 - val_accuracy: 0.9803\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLmCtq-LnkxX"
      },
      "source": [
        "**Plotting a validation accuracy comparison**\n",
        "\n",
        "**繪圖後發現，加入噪音的數據使最終訓練準確率降低，因為噪音本身提供了部分錯誤的相關性訊息使其擬合無法完全理想。此外，CH4在一開始挑出10000的最高頻率出現的單字，也是為了避免訊息資訊的偏差。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "EU8s64WMnkxX",
        "outputId": "7b0b2efe-3cce-45cd-bcbb-55d7c0dc98b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd9405036d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeBRC3SXnkxX"
      },
      "source": [
        "### The nature of generalization in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5uc7z65nkxX"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**\n",
        "\n",
        "**使用完全隨機之標籤訓練資料，仍有不差的訓練準確率，是因為模型能自行尋找訓練數據集的規律；但驗證準確率極糟，因為模型早已過度擬合，泛化性亦極差**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyE2OPJDnkxY",
        "outputId": "9a762cf9-5d03-4f9e-ed0d-1e26d1108242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 2.3189 - accuracy: 0.1026 - val_loss: 2.3067 - val_accuracy: 0.0978\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.3003 - accuracy: 0.1159 - val_loss: 2.3115 - val_accuracy: 0.1040\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2924 - accuracy: 0.1242 - val_loss: 2.3192 - val_accuracy: 0.0972\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2792 - accuracy: 0.1376 - val_loss: 2.3278 - val_accuracy: 0.1037\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2614 - accuracy: 0.1530 - val_loss: 2.3378 - val_accuracy: 0.0993\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2407 - accuracy: 0.1674 - val_loss: 2.3454 - val_accuracy: 0.1028\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.2166 - accuracy: 0.1811 - val_loss: 2.3638 - val_accuracy: 0.1031\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.1892 - accuracy: 0.1988 - val_loss: 2.3833 - val_accuracy: 0.0986\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.1614 - accuracy: 0.2136 - val_loss: 2.4036 - val_accuracy: 0.1002\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 2.1305 - accuracy: 0.2286 - val_loss: 2.4189 - val_accuracy: 0.0992\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.0972 - accuracy: 0.2434 - val_loss: 2.4464 - val_accuracy: 0.1001\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.0643 - accuracy: 0.2597 - val_loss: 2.4707 - val_accuracy: 0.1048\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.0274 - accuracy: 0.2781 - val_loss: 2.5132 - val_accuracy: 0.1003\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9947 - accuracy: 0.2901 - val_loss: 2.5336 - val_accuracy: 0.0996\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9586 - accuracy: 0.3072 - val_loss: 2.5747 - val_accuracy: 0.0994\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.9245 - accuracy: 0.3204 - val_loss: 2.5934 - val_accuracy: 0.1025\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.8909 - accuracy: 0.3348 - val_loss: 2.6283 - val_accuracy: 0.1004\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.8571 - accuracy: 0.3452 - val_loss: 2.6709 - val_accuracy: 0.1003\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.8237 - accuracy: 0.3613 - val_loss: 2.7064 - val_accuracy: 0.1010\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.7919 - accuracy: 0.3733 - val_loss: 2.7369 - val_accuracy: 0.1044\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.7602 - accuracy: 0.3851 - val_loss: 2.7776 - val_accuracy: 0.1002\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.7279 - accuracy: 0.3989 - val_loss: 2.8197 - val_accuracy: 0.1041\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.6979 - accuracy: 0.4097 - val_loss: 2.8483 - val_accuracy: 0.1040\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.6672 - accuracy: 0.4231 - val_loss: 2.8796 - val_accuracy: 0.1046\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.6384 - accuracy: 0.4333 - val_loss: 2.9573 - val_accuracy: 0.1004\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.6107 - accuracy: 0.4434 - val_loss: 2.9717 - val_accuracy: 0.1023\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5837 - accuracy: 0.4544 - val_loss: 3.0049 - val_accuracy: 0.1037\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5546 - accuracy: 0.4624 - val_loss: 3.0511 - val_accuracy: 0.1035\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5290 - accuracy: 0.4735 - val_loss: 3.1017 - val_accuracy: 0.0993\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.5038 - accuracy: 0.4836 - val_loss: 3.1380 - val_accuracy: 0.1004\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4763 - accuracy: 0.4919 - val_loss: 3.1987 - val_accuracy: 0.1011\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.4498 - accuracy: 0.5041 - val_loss: 3.2274 - val_accuracy: 0.0998\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.4271 - accuracy: 0.5113 - val_loss: 3.2609 - val_accuracy: 0.1001\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4019 - accuracy: 0.5222 - val_loss: 3.3180 - val_accuracy: 0.1021\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3761 - accuracy: 0.5309 - val_loss: 3.3806 - val_accuracy: 0.1011\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3555 - accuracy: 0.5380 - val_loss: 3.4280 - val_accuracy: 0.1004\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3319 - accuracy: 0.5472 - val_loss: 3.4919 - val_accuracy: 0.1039\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.3112 - accuracy: 0.5533 - val_loss: 3.5069 - val_accuracy: 0.1028\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2873 - accuracy: 0.5644 - val_loss: 3.5698 - val_accuracy: 0.1017\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2673 - accuracy: 0.5704 - val_loss: 3.6286 - val_accuracy: 0.1018\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2455 - accuracy: 0.5777 - val_loss: 3.6838 - val_accuracy: 0.1003\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2233 - accuracy: 0.5857 - val_loss: 3.7285 - val_accuracy: 0.1020\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2065 - accuracy: 0.5919 - val_loss: 3.7740 - val_accuracy: 0.1023\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1848 - accuracy: 0.6002 - val_loss: 3.8425 - val_accuracy: 0.0999\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1682 - accuracy: 0.6082 - val_loss: 3.8647 - val_accuracy: 0.0989\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1478 - accuracy: 0.6130 - val_loss: 3.9344 - val_accuracy: 0.1018\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1291 - accuracy: 0.6176 - val_loss: 3.9870 - val_accuracy: 0.1024\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1125 - accuracy: 0.6255 - val_loss: 4.0549 - val_accuracy: 0.1001\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 1.0958 - accuracy: 0.6326 - val_loss: 4.0938 - val_accuracy: 0.0975\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0750 - accuracy: 0.6367 - val_loss: 4.1712 - val_accuracy: 0.1004\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0582 - accuracy: 0.6460 - val_loss: 4.2246 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0436 - accuracy: 0.6500 - val_loss: 4.2840 - val_accuracy: 0.1007\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0268 - accuracy: 0.6552 - val_loss: 4.3524 - val_accuracy: 0.1016\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.0097 - accuracy: 0.6603 - val_loss: 4.3927 - val_accuracy: 0.0996\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9953 - accuracy: 0.6666 - val_loss: 4.4425 - val_accuracy: 0.1053\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9786 - accuracy: 0.6724 - val_loss: 4.4838 - val_accuracy: 0.1029\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9637 - accuracy: 0.6789 - val_loss: 4.5523 - val_accuracy: 0.1004\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9497 - accuracy: 0.6849 - val_loss: 4.6283 - val_accuracy: 0.1013\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9351 - accuracy: 0.6893 - val_loss: 4.6645 - val_accuracy: 0.1015\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9215 - accuracy: 0.6944 - val_loss: 4.7598 - val_accuracy: 0.1018\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9059 - accuracy: 0.6989 - val_loss: 4.7906 - val_accuracy: 0.1025\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8936 - accuracy: 0.7037 - val_loss: 4.8661 - val_accuracy: 0.0990\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8805 - accuracy: 0.7071 - val_loss: 4.9194 - val_accuracy: 0.0993\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8674 - accuracy: 0.7119 - val_loss: 4.9988 - val_accuracy: 0.1018\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.8536 - accuracy: 0.7171 - val_loss: 5.0143 - val_accuracy: 0.0986\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8411 - accuracy: 0.7212 - val_loss: 5.0852 - val_accuracy: 0.0981\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8296 - accuracy: 0.7243 - val_loss: 5.1350 - val_accuracy: 0.0994\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8158 - accuracy: 0.7310 - val_loss: 5.2446 - val_accuracy: 0.1018\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8051 - accuracy: 0.7335 - val_loss: 5.2730 - val_accuracy: 0.0988\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7911 - accuracy: 0.7384 - val_loss: 5.3602 - val_accuracy: 0.0988\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7800 - accuracy: 0.7428 - val_loss: 5.4207 - val_accuracy: 0.0990\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7676 - accuracy: 0.7451 - val_loss: 5.4388 - val_accuracy: 0.0962\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7593 - accuracy: 0.7484 - val_loss: 5.5727 - val_accuracy: 0.1007\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7471 - accuracy: 0.7540 - val_loss: 5.5800 - val_accuracy: 0.0990\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7340 - accuracy: 0.7595 - val_loss: 5.6774 - val_accuracy: 0.0967\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7243 - accuracy: 0.7632 - val_loss: 5.7450 - val_accuracy: 0.1008\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7115 - accuracy: 0.7674 - val_loss: 5.8361 - val_accuracy: 0.1025\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7042 - accuracy: 0.7680 - val_loss: 5.8526 - val_accuracy: 0.1028\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.7726 - val_loss: 5.9860 - val_accuracy: 0.0997\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6836 - accuracy: 0.7756 - val_loss: 6.0249 - val_accuracy: 0.1021\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6727 - accuracy: 0.7797 - val_loss: 6.0477 - val_accuracy: 0.1030\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6645 - accuracy: 0.7838 - val_loss: 6.1022 - val_accuracy: 0.1016\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6545 - accuracy: 0.7850 - val_loss: 6.1638 - val_accuracy: 0.1048\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6443 - accuracy: 0.7894 - val_loss: 6.2600 - val_accuracy: 0.1015\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.6360 - accuracy: 0.7944 - val_loss: 6.3409 - val_accuracy: 0.0995\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6256 - accuracy: 0.7959 - val_loss: 6.4020 - val_accuracy: 0.0994\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6165 - accuracy: 0.8005 - val_loss: 6.5061 - val_accuracy: 0.1002\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6087 - accuracy: 0.8012 - val_loss: 6.4902 - val_accuracy: 0.1011\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6011 - accuracy: 0.8035 - val_loss: 6.5935 - val_accuracy: 0.1005\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.8075 - val_loss: 6.6992 - val_accuracy: 0.1011\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5827 - accuracy: 0.8109 - val_loss: 6.7440 - val_accuracy: 0.1000\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5737 - accuracy: 0.8140 - val_loss: 6.7558 - val_accuracy: 0.1047\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5659 - accuracy: 0.8160 - val_loss: 6.8746 - val_accuracy: 0.1007\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5584 - accuracy: 0.8180 - val_loss: 6.9111 - val_accuracy: 0.1007\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5504 - accuracy: 0.8229 - val_loss: 6.9712 - val_accuracy: 0.1007\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5412 - accuracy: 0.8249 - val_loss: 7.0676 - val_accuracy: 0.1021\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5349 - accuracy: 0.8279 - val_loss: 7.1163 - val_accuracy: 0.1032\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5236 - accuracy: 0.8313 - val_loss: 7.1693 - val_accuracy: 0.1033\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5215 - accuracy: 0.8317 - val_loss: 7.2590 - val_accuracy: 0.1008\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5125 - accuracy: 0.8354 - val_loss: 7.3720 - val_accuracy: 0.1026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd940749ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, random_train_labels,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GntG0bAQnkxY"
      },
      "source": [
        "#### The manifold hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTnIT11lnkxY"
      },
      "source": [
        "#### Interpolation as a source of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_knFHvnnkxY"
      },
      "source": [
        "#### Why deep learning works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYk8LC76nkxY"
      },
      "source": [
        "#### Training data is paramount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOnz0gWlnkxY"
      },
      "source": [
        "## Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzvFbbX9nkxZ"
      },
      "source": [
        "### Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NHfHb_5nkxZ"
      },
      "source": [
        "#### Simple hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8atkqoqnkxZ"
      },
      "source": [
        "#### K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2xPykI1nkxZ"
      },
      "source": [
        "#### Iterated K-fold validation with shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J43cgd7nkxZ"
      },
      "source": [
        "### Beating a common-sense baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSfprKhUnkxZ"
      },
      "source": [
        "### Things to keep in mind about model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wm_9ixEnkxZ"
      },
      "source": [
        "## Improving model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdGnrLnAnkxZ"
      },
      "source": [
        "### Tuning key gradient descent parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRX50n7Pnkxa"
      },
      "source": [
        "**Training a MNIST model with an incorrectly high learning rate**\n",
        "\n",
        "**不當的參數設定會使模型訓練無法達成理想結果，如：學習率設置過高。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHCAI03Vnkxa",
        "outputId": "4cdf20d0-3617-4863-8c7f-daef1fa97960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 806.3513 - accuracy: 0.3910 - val_loss: 3.0697 - val_accuracy: 0.3219\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 3.8888 - accuracy: 0.2769 - val_loss: 2.5701 - val_accuracy: 0.2923\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.7391 - accuracy: 0.2691 - val_loss: 2.7825 - val_accuracy: 0.2365\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.6552 - accuracy: 0.2379 - val_loss: 2.2301 - val_accuracy: 0.2313\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.7584 - accuracy: 0.2472 - val_loss: 3.2408 - val_accuracy: 0.2642\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.8527 - accuracy: 0.2399 - val_loss: 2.5243 - val_accuracy: 0.2755\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.8884 - accuracy: 0.2541 - val_loss: 1.9827 - val_accuracy: 0.2641\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.6056 - accuracy: 0.2389 - val_loss: 2.2678 - val_accuracy: 0.2488\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.4448 - accuracy: 0.2737 - val_loss: 2.1071 - val_accuracy: 0.2627\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 2.4824 - accuracy: 0.2662 - val_loss: 2.2787 - val_accuracy: 0.3264\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd9402aa9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.), # 學習率 1 (過高)\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKm38vYTnkxa"
      },
      "source": [
        "**The same model with a more appropriate learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4eVMnBjnkxa",
        "outputId": "6ec6a1be-37fb-4bbf-d07c-279115d52235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3710 - accuracy: 0.9117 - val_loss: 0.2212 - val_accuracy: 0.9401\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1400 - accuracy: 0.9636 - val_loss: 0.1543 - val_accuracy: 0.9613\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1109 - accuracy: 0.9737 - val_loss: 0.1644 - val_accuracy: 0.9681\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9775 - val_loss: 0.2209 - val_accuracy: 0.9645\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9814 - val_loss: 0.1991 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0791 - accuracy: 0.9836 - val_loss: 0.1903 - val_accuracy: 0.9724\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0728 - accuracy: 0.9867 - val_loss: 0.2527 - val_accuracy: 0.9729\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0728 - accuracy: 0.9869 - val_loss: 0.2689 - val_accuracy: 0.9754\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0639 - accuracy: 0.9894 - val_loss: 0.2834 - val_accuracy: 0.9742\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0553 - accuracy: 0.9903 - val_loss: 0.2761 - val_accuracy: 0.9747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd94073eed0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2), # 學習率 0.01 (合適)\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TAHlvRknkxa"
      },
      "source": [
        "### Leveraging better architecture priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBcp6-YEnkxa"
      },
      "source": [
        "### Increasing model capacity\n",
        "\n",
        "**模型似乎達不到最佳擬合結果時，可能是因為模型存儲信息的容量太少，因此可以嘗試增加模型結構複雜度或神經元數**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLU7Bxy_nkxa"
      },
      "source": [
        "**A simple logistic regression on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o9Zg0aPnkxb",
        "outputId": "3b401a30-3031-467c-c0d1-ca6297b0b450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.6662 - accuracy: 0.8332 - val_loss: 0.3556 - val_accuracy: 0.9059\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3513 - accuracy: 0.9029 - val_loss: 0.3063 - val_accuracy: 0.9159\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.9124 - val_loss: 0.2894 - val_accuracy: 0.9201\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.9165 - val_loss: 0.2818 - val_accuracy: 0.9227\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9187 - val_loss: 0.2750 - val_accuracy: 0.9239\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2828 - accuracy: 0.9210 - val_loss: 0.2733 - val_accuracy: 0.9252\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9227 - val_loss: 0.2692 - val_accuracy: 0.9266\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.9233 - val_loss: 0.2671 - val_accuracy: 0.9270\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.9245 - val_loss: 0.2655 - val_accuracy: 0.9290\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.9252 - val_loss: 0.2647 - val_accuracy: 0.9285\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.9265 - val_loss: 0.2650 - val_accuracy: 0.9283\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.9267 - val_loss: 0.2645 - val_accuracy: 0.9285\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2633 - accuracy: 0.9273 - val_loss: 0.2622 - val_accuracy: 0.9291\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.9272 - val_loss: 0.2624 - val_accuracy: 0.9306\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.9288 - val_loss: 0.2618 - val_accuracy: 0.9300\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.9286 - val_loss: 0.2646 - val_accuracy: 0.9289\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.9295 - val_loss: 0.2624 - val_accuracy: 0.9300\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.9295 - val_loss: 0.2605 - val_accuracy: 0.9312\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.9301 - val_loss: 0.2620 - val_accuracy: 0.9306\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9304 - val_loss: 0.2617 - val_accuracy: 0.9303\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_small_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "3LvQ4H9rnkxb",
        "outputId": "aa3dd9ba-d0c4-4823-f345-f5ead9e08e2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd8e6615a90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_small_model.history[\"val_loss\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_loss, \"b--\",\n",
        "         label=\"Validation loss\")\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK-QiRa-nkxb",
        "outputId": "5df3554c-59c8-43d4-d28f-0af8911dce44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3609 - accuracy: 0.8989 - val_loss: 0.2095 - val_accuracy: 0.9388\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9526 - val_loss: 0.1364 - val_accuracy: 0.9596\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9664 - val_loss: 0.1180 - val_accuracy: 0.9654\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9739 - val_loss: 0.1075 - val_accuracy: 0.9699\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9792 - val_loss: 0.1072 - val_accuracy: 0.9699\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 0.0992 - val_accuracy: 0.9731\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9854 - val_loss: 0.1083 - val_accuracy: 0.9717\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0968 - val_accuracy: 0.9749\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0975 - val_accuracy: 0.9747\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.1055 - val_accuracy: 0.9743\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.1098 - val_accuracy: 0.9742\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.1172 - val_accuracy: 0.9737\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.1282 - val_accuracy: 0.9721\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.1209 - val_accuracy: 0.9746\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.1255 - val_accuracy: 0.9739\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1374 - val_accuracy: 0.9743\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.1462 - val_accuracy: 0.9739\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1480 - val_accuracy: 0.9735\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1509 - val_accuracy: 0.9737\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1518 - val_accuracy: 0.9759\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_large_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HStcSImynkxb"
      },
      "source": [
        "## Improving generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4JuG67rnkxb"
      },
      "source": [
        "### Dataset curation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLsQexVpnkxb"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8iXrHk5nkxb"
      },
      "source": [
        "### Using early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfBR8i0znkxb"
      },
      "source": [
        "### Regularizing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh_Mtpn1nkxc"
      },
      "source": [
        "#### Reducing the network's size\n",
        "\n",
        "**正則化(Regularizing)：使曲線更簡單、平滑、足夠泛化**\n",
        "\n",
        "**縮小訓練模型的體積能夠讓過度擬合的出現時間變得更晚，並且過度擬合後的泛化下降程度也更趨緩**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJyJ_k1Enkxc"
      },
      "source": [
        "**Original model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIXecQ5Jnkxc",
        "outputId": "d3c0bd48-66b4-4a3b-cd28-81c7139b9d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 40ms/step - loss: 0.5553 - accuracy: 0.7673 - val_loss: 0.4074 - val_accuracy: 0.8683\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3316 - accuracy: 0.8956 - val_loss: 0.3127 - val_accuracy: 0.8852\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2400 - accuracy: 0.9201 - val_loss: 0.2855 - val_accuracy: 0.8891\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1878 - accuracy: 0.9399 - val_loss: 0.2722 - val_accuracy: 0.8914\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1497 - accuracy: 0.9524 - val_loss: 0.2760 - val_accuracy: 0.8899\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1250 - accuracy: 0.9610 - val_loss: 0.2879 - val_accuracy: 0.8871\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1034 - accuracy: 0.9687 - val_loss: 0.3065 - val_accuracy: 0.8835\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0850 - accuracy: 0.9756 - val_loss: 0.3356 - val_accuracy: 0.8804\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0692 - accuracy: 0.9819 - val_loss: 0.3542 - val_accuracy: 0.8790\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0559 - accuracy: 0.9855 - val_loss: 0.3809 - val_accuracy: 0.8776\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0484 - accuracy: 0.9888 - val_loss: 0.4092 - val_accuracy: 0.8755\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0365 - accuracy: 0.9926 - val_loss: 0.4308 - val_accuracy: 0.8753\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0299 - accuracy: 0.9941 - val_loss: 0.4760 - val_accuracy: 0.8732\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0268 - accuracy: 0.9943 - val_loss: 0.4945 - val_accuracy: 0.8741\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0177 - accuracy: 0.9971 - val_loss: 0.5242 - val_accuracy: 0.8714\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0143 - accuracy: 0.9979 - val_loss: 0.5670 - val_accuracy: 0.8694\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.6263 - val_accuracy: 0.8674\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.6368 - val_accuracy: 0.8664\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.6825 - val_accuracy: 0.8654\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.7154 - val_accuracy: 0.8664\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z324Rzl7nkxc"
      },
      "source": [
        "**Version of the model with lower capacity**\n",
        "\n",
        "較小的模型較晚過度擬合(訓練週期4-->6)，且過度擬合以後的驗證曲線變化也較為趨緩\n",
        "\n",
        "<img src=\"https://i.imgur.com/HSI8fRa.jpg\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R97Lc-70nkxc",
        "outputId": "1efa36a4-3a82-454d-8f6b-3ddfa1312c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 35ms/step - loss: 0.6687 - accuracy: 0.5694 - val_loss: 0.6437 - val_accuracy: 0.7192\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.6139 - accuracy: 0.7084 - val_loss: 0.5960 - val_accuracy: 0.7650\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5630 - accuracy: 0.7737 - val_loss: 0.5552 - val_accuracy: 0.7789\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.5187 - accuracy: 0.8213 - val_loss: 0.5231 - val_accuracy: 0.8349\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.4828 - accuracy: 0.8565 - val_loss: 0.4977 - val_accuracy: 0.8462\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.4527 - accuracy: 0.8803 - val_loss: 0.4789 - val_accuracy: 0.8562\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4270 - accuracy: 0.9000 - val_loss: 0.4651 - val_accuracy: 0.8642\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4052 - accuracy: 0.9142 - val_loss: 0.4531 - val_accuracy: 0.8758\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3857 - accuracy: 0.9287 - val_loss: 0.4491 - val_accuracy: 0.8696\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3683 - accuracy: 0.9367 - val_loss: 0.4480 - val_accuracy: 0.8690\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.3519 - accuracy: 0.9449 - val_loss: 0.4498 - val_accuracy: 0.8692\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3374 - accuracy: 0.9519 - val_loss: 0.4565 - val_accuracy: 0.8670\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3240 - accuracy: 0.9577 - val_loss: 0.4514 - val_accuracy: 0.8717\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3117 - accuracy: 0.9638 - val_loss: 0.4537 - val_accuracy: 0.8741\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3001 - accuracy: 0.9691 - val_loss: 0.4717 - val_accuracy: 0.8659\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2895 - accuracy: 0.9723 - val_loss: 0.4597 - val_accuracy: 0.8730\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2791 - accuracy: 0.9763 - val_loss: 0.4562 - val_accuracy: 0.8784\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2697 - accuracy: 0.9783 - val_loss: 0.4867 - val_accuracy: 0.8693\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2608 - accuracy: 0.9801 - val_loss: 0.5162 - val_accuracy: 0.8633\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2522 - accuracy: 0.9816 - val_loss: 0.5191 - val_accuracy: 0.8665\n"
          ]
        }
      ],
      "source": [
        "# 模型由16x16x1縮小為4x4x1\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_smaller_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y9vhGQCnkxc"
      },
      "source": [
        "**Version of the model with higher capacity**\n",
        "\n",
        "**太大的模型，過度擬合更早發生，驗證損失曲線不穩定且方差更大**\n",
        "\n",
        "<img src=\"https://i.imgur.com/mIT7eB5.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSKazSH2nkxc",
        "outputId": "1a5b7c17-e5e8-4964-da7e-81bc338eb228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 42ms/step - loss: 0.5317 - accuracy: 0.7648 - val_loss: 0.3427 - val_accuracy: 0.8632\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.2510 - accuracy: 0.8983 - val_loss: 0.2974 - val_accuracy: 0.8835\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.1383 - accuracy: 0.9477 - val_loss: 0.3008 - val_accuracy: 0.8843\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.1231 - accuracy: 0.9699 - val_loss: 0.3329 - val_accuracy: 0.8898\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.4912 - val_accuracy: 0.8794\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0509 - accuracy: 0.9941 - val_loss: 0.8740 - val_accuracy: 0.8250\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.5833 - val_accuracy: 0.8875\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 3.4092e-04 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8852\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1549 - accuracy: 0.9793 - val_loss: 0.5243 - val_accuracy: 0.8834\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 4.0874e-04 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.8858\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 1.0650e-04 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.8813\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 3.0319e-05 - accuracy: 1.0000 - val_loss: 0.8192 - val_accuracy: 0.8849\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 7.3286e-06 - accuracy: 1.0000 - val_loss: 0.9313 - val_accuracy: 0.8849\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 1.9988e-06 - accuracy: 1.0000 - val_loss: 1.0226 - val_accuracy: 0.8848\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 6.0984e-07 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.8814\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 2.2419e-07 - accuracy: 1.0000 - val_loss: 1.1854 - val_accuracy: 0.8820\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 8.7338e-08 - accuracy: 1.0000 - val_loss: 1.2500 - val_accuracy: 0.8835\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 4.0885e-08 - accuracy: 1.0000 - val_loss: 1.2978 - val_accuracy: 0.8834\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 2.4000e-08 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.8832\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 1.6567e-08 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.8840\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_larger_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCIZ5a1Snkxd"
      },
      "source": [
        "#### Adding weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**奧卡姆剃⼑原理(principle of Occam’s razor)**\n",
        "\n",
        "對於某事給出兩種解釋，最有可能正確的解釋是最簡單的解釋。類推至神經網路模型，簡單的模型較複雜的模型更不容易過度擬合。"
      ],
      "metadata": {
        "id": "P9Tfwu2aNwVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**權重正則化(weight regularization)**\n",
        "\n",
        "也就是權重限制法。強制給定訓練權重之上、下限，使參數訓練時不會過大或過小，使權重分布更常規性(減輕模型複雜度)，避免過度擬合情形。形式上有：\n",
        "* **L1 regulation：** The cost added is proportional to the absolute value of the weight coefficients (增加的cost與權重係數**絕對值**成正比)\n",
        "* **L2 regulation：** The cost added is proportional to the square of the value of the weight coefficients (增加的cost與權重係數**平方**成正比)"
      ],
      "metadata": {
        "id": "dB3GCvtgO_AY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z68Io0oOnkxd"
      },
      "source": [
        "**Adding L2 weight regularization to the model**\n",
        "\n",
        "`kernel_regularizer=regularizers.l2(0.002)`：將各層權重矩陣的每一個係數值增加`(0.002 * weight_coefficient_value ** 2)`至模型總損失。最終發現經L2正則化的模型更能對抗過度擬合。\n",
        "\n",
        "<img src=\"https://i.imgur.com/agOAGTq.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lvgdZOhnkxd",
        "outputId": "9b5c6495-820a-480e-b52d-6b779ceb1ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 36ms/step - loss: 0.5872 - accuracy: 0.7932 - val_loss: 0.5008 - val_accuracy: 0.8179\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3967 - accuracy: 0.8955 - val_loss: 0.3906 - val_accuracy: 0.8830\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3275 - accuracy: 0.9171 - val_loss: 0.3745 - val_accuracy: 0.8818\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2971 - accuracy: 0.9251 - val_loss: 0.3582 - val_accuracy: 0.8903\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2797 - accuracy: 0.9303 - val_loss: 0.3598 - val_accuracy: 0.8871\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2643 - accuracy: 0.9369 - val_loss: 0.3702 - val_accuracy: 0.8839\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2570 - accuracy: 0.9402 - val_loss: 0.3818 - val_accuracy: 0.8798\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2494 - accuracy: 0.9440 - val_loss: 0.3831 - val_accuracy: 0.8799\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2415 - accuracy: 0.9464 - val_loss: 0.3772 - val_accuracy: 0.8833\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2370 - accuracy: 0.9493 - val_loss: 0.4345 - val_accuracy: 0.8620\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2339 - accuracy: 0.9491 - val_loss: 0.3852 - val_accuracy: 0.8783\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2295 - accuracy: 0.9523 - val_loss: 0.4451 - val_accuracy: 0.8675\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2242 - accuracy: 0.9519 - val_loss: 0.4299 - val_accuracy: 0.8662\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2232 - accuracy: 0.9527 - val_loss: 0.4071 - val_accuracy: 0.8764\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2252 - accuracy: 0.9510 - val_loss: 0.4092 - val_accuracy: 0.8770\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2140 - accuracy: 0.9577 - val_loss: 0.4179 - val_accuracy: 0.8752\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2132 - accuracy: 0.9539 - val_loss: 0.4076 - val_accuracy: 0.8765\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2156 - accuracy: 0.9543 - val_loss: 0.4119 - val_accuracy: 0.8749\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2052 - accuracy: 0.9599 - val_loss: 0.4217 - val_accuracy: 0.8748\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2088 - accuracy: 0.9553 - val_loss: 0.4181 - val_accuracy: 0.8773\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_l2_reg = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnr_2lLfnkxd"
      },
      "source": [
        "**Different weight regularizers available in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UUPwA3mnkxd",
        "outputId": "11a3e62c-b44a-46d2-9903-7ebca4002e9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.regularizers.L1L2 at 0x7fd8365cc610>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "regularizers.l1(0.001)\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kql5WdWCnkxd"
      },
      "source": [
        "#### Adding dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPJgu0Ignkxd"
      },
      "source": [
        "**Adding dropout to the IMDB model**\n",
        "\n",
        "**使用Dropout層也能減輕過度擬合**\n",
        "\n",
        "<img src=\"https://i.imgur.com/6WNCcHu.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItFs0bWUnkxe",
        "outputId": "3ddd44db-d18b-412e-b3fc-a0b880f6083f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 36ms/step - loss: 0.6418 - accuracy: 0.6385 - val_loss: 0.5467 - val_accuracy: 0.8446\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.5401 - accuracy: 0.7496 - val_loss: 0.4549 - val_accuracy: 0.8695\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4673 - accuracy: 0.8099 - val_loss: 0.3862 - val_accuracy: 0.8807\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3993 - accuracy: 0.8533 - val_loss: 0.3360 - val_accuracy: 0.8838\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3524 - accuracy: 0.8753 - val_loss: 0.3029 - val_accuracy: 0.8882\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3104 - accuracy: 0.8943 - val_loss: 0.2967 - val_accuracy: 0.8903\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2785 - accuracy: 0.9072 - val_loss: 0.2821 - val_accuracy: 0.8854\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2422 - accuracy: 0.9209 - val_loss: 0.2837 - val_accuracy: 0.8855\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2229 - accuracy: 0.9290 - val_loss: 0.3021 - val_accuracy: 0.8903\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1995 - accuracy: 0.9376 - val_loss: 0.3011 - val_accuracy: 0.8873\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1850 - accuracy: 0.9413 - val_loss: 0.3199 - val_accuracy: 0.8826\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1672 - accuracy: 0.9480 - val_loss: 0.3617 - val_accuracy: 0.8903\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1461 - accuracy: 0.9536 - val_loss: 0.4109 - val_accuracy: 0.8866\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1449 - accuracy: 0.9569 - val_loss: 0.3761 - val_accuracy: 0.8845\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1308 - accuracy: 0.9599 - val_loss: 0.4000 - val_accuracy: 0.8811\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1277 - accuracy: 0.9608 - val_loss: 0.4617 - val_accuracy: 0.8870\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1126 - accuracy: 0.9668 - val_loss: 0.4751 - val_accuracy: 0.8844\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1075 - accuracy: 0.9677 - val_loss: 0.5138 - val_accuracy: 0.8841\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1031 - accuracy: 0.9703 - val_loss: 0.5242 - val_accuracy: 0.8826\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0962 - accuracy: 0.9729 - val_loss: 0.5553 - val_accuracy: 0.8841\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5), # Drop out 50% 的數據\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5), # Drop out 50% 的數據\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_dropout = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89WDOrlMnkxe"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "請看本文章最頂處，我在文初做好了摘要"
      ],
      "metadata": {
        "id": "py2fErFZXk6-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}